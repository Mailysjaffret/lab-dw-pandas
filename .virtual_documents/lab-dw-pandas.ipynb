

















import pandas as pd


insurance_df = pd.read_csv("https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv")


insurance_df


insurance_df.shape


insurance_df.dtypes





insurance_df.nunique()





numerical_summary = insurance_df.describe()
print(numerical_summary)


categorical_columns = insurance_df.select_dtypes(include=["object"]).columns
categorical_summary = insurance_df[categorical_columns].describe()
print(categorical_summary)





## Challenge 2: analyzing the data








location_frequencies = insurance_df['ST'].value_counts()
location_frequencies


top_5_less_common_locations = location_frequencies.nsmallest(5)
top_5_less_common_locations











policy_type_frequencies = insurance_df['Policy Type'].value_counts()
policy_type_frequencies


most_sold_policy_type = policy_type_frequencies.idxmax()
most_sold_policy_type








personal_auto_df = insurance_df.loc[insurance_df['Policy Type'] == 'Personal Auto']
corporate_auto_df = insurance_df.loc[insurance_df['Policy Type'] == 'Corporate Auto']

average_income_personal_auto = personal_auto_df['Income'].mean()
average_income_corporate_auto = corporate_auto_df['Income'].mean()

print(average_income_personal_auto)
print(average_income_corporate_auto)

















claim_75th_percentile = insurance_df['Total Claim Amount'].quantile(0.75)

high_claims_df = insurance_df[insurance_df['Total Claim Amount'] > claim_75th_percentile]

high_claims_stats = high_claims_df.describe()
print(high_claims_stats)






